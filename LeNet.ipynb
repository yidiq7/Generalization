{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PruningModule(Module):\n",
    "    def prune_by_percentile(self, q=5.0, **kwargs):\n",
    "        \"\"\"\n",
    "        Note:\n",
    "             The pruning percentile is based on all layer's parameters concatenated\n",
    "        Args:\n",
    "            q (float): percentile in float\n",
    "            **kwargs: may contain `cuda`\n",
    "        \"\"\"\n",
    "        # Calculate percentile value\n",
    "        alive_parameters = []\n",
    "        for name, p in self.named_parameters():\n",
    "            # We do not prune bias term\n",
    "            if 'bias' in name or 'mask' in name:\n",
    "                continue\n",
    "            tensor = p.data.cpu().numpy()\n",
    "            alive = tensor[np.nonzero(tensor)] # flattened array of nonzero values\n",
    "            alive_parameters.append(alive)\n",
    "\n",
    "        all_alives = np.concatenate(alive_parameters)\n",
    "        percentile_value = np.percentile(abs(all_alives), q)\n",
    "        print(f'Pruning with threshold : {percentile_value}')\n",
    "\n",
    "        # Prune the weights and mask\n",
    "        # Note that module here is the layer\n",
    "        # ex) fc1, fc2, fc3\n",
    "        for name, module in self.named_modules():\n",
    "            if name in ['fc1', 'fc2','fc3']:\n",
    "                module.prune(threshold=percentile_value)\n",
    "\n",
    "    def prune_by_std(self, s=0.25):\n",
    "        \"\"\"\n",
    "        Note that `s` is a quality parameter / sensitivity value according to the paper.\n",
    "        According to Song Han's previous paper (Learning both Weights and Connections for Efficient Neural Networks),\n",
    "        'The pruning threshold is chosen as a quality parameter multiplied by the standard deviation of a layerâ€™s weights'\n",
    "\n",
    "        I tried multiple values and empirically, 0.25 matches the paper's compression rate and number of parameters.\n",
    "        Note : In the paper, the authors used different sensitivity values for different layers.\n",
    "        \"\"\"\n",
    "        for name, module in self.named_modules():\n",
    "            if name in ['fc1', 'fc2','fc3']:\n",
    "                threshold = np.std(module.weight.data.cpu().numpy()) * s\n",
    "                print(f'Pruning with threshold : {threshold} for layer {name}')\n",
    "                module.prune(threshold)\n",
    "\n",
    "\n",
    "class MaskedLinear(Module):\n",
    "    \"\"\"Applies a masked linear transformation to the incoming data: :math:`y = (A * M)x + b`\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
    "          additional dimensions\n",
    "        - Output: :math:`(N, *, out\\_features)` where all but the last dimension\n",
    "          are the same shape as the input.\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "        mask: the unlearnable mask for the weight.\n",
    "            It has the same shape as weight (out_features x in_features)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        # Initialize the mask with 1\n",
    "        self.mask = Parameter(torch.ones([out_features, in_features]), requires_grad=False)\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight * self.mask, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'\n",
    "\n",
    "    def prune(self, threshold):\n",
    "        weight_dev = self.weight.device\n",
    "        mask_dev = self.mask.device\n",
    "        # Convert Tensors to numpy and calculate\n",
    "        tensor = self.weight.data.cpu().numpy()\n",
    "        mask = self.mask.data.cpu().numpy()\n",
    "        new_mask = np.where(abs(tensor) < threshold, 0.0, mask)\n",
    "        # Apply new weight and mask\n",
    "        self.weight.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
    "        self.mask.data = torch.from_numpy(new_mask).to(mask_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "      MaskedLinear-5                  [-1, 120]          48,120\n",
      "      MaskedLinear-6                   [-1, 84]          10,164\n",
      "      MaskedLinear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net(PruningModule):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        linear = MaskedLinear\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = linear(120, 84)\n",
    "        self.fc3 = linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "summary(net, (3, 32, 32))\n",
    "# Freeze the first layer\n",
    "#for param in net.fc1.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "# Initialize the first layer\n",
    "#def weights_init(m):\n",
    "#    if isinstance(m, nn.Linear):\n",
    "#        m.weight.data.normal_(0, 0.01)\n",
    "    \n",
    "#net.apply(weights_init)\n",
    "\n",
    "#net.prune_by_std()\n",
    "\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params[4] are weights in the first layer, params[5] are the masks, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Parameter containing:\n",
      "tensor([[-0.0214, -0.0039, -0.0270,  ..., -0.0166, -0.0090, -0.0218],\n",
      "        [-0.0334, -0.0108, -0.0015,  ..., -0.0237,  0.0226, -0.0432],\n",
      "        [ 0.0433, -0.0383,  0.0144,  ..., -0.0284, -0.0414,  0.0333],\n",
      "        ...,\n",
      "        [ 0.0197, -0.0304, -0.0278,  ..., -0.0384,  0.0454,  0.0064],\n",
      "        [-0.0260, -0.0139, -0.0254,  ...,  0.0478,  0.0123,  0.0180],\n",
      "        [ 0.0257, -0.0456, -0.0299,  ..., -0.0418,  0.0291,  0.0163]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Softmax is built in it so you do not need add that on the last layer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "initial_optimizer_state_dict = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 1000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "            # training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        print('Train Accuracy: %.2f %%' % (100 * train_correct / train_total))\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.303\n",
      "[1,   400] loss: 2.301\n",
      "[1,   600] loss: 2.300\n",
      "Train Accuracy: 10.57 %\n",
      "[2,   200] loss: 2.289\n",
      "[2,   400] loss: 2.273\n",
      "[2,   600] loss: 2.229\n",
      "Train Accuracy: 19.07 %\n",
      "[3,   200] loss: 2.026\n",
      "[3,   400] loss: 1.976\n",
      "[3,   600] loss: 1.929\n",
      "Train Accuracy: 28.65 %\n",
      "[4,   200] loss: 1.854\n",
      "[4,   400] loss: 1.804\n",
      "[4,   600] loss: 1.751\n",
      "Train Accuracy: 34.87 %\n",
      "[5,   200] loss: 1.670\n",
      "[5,   400] loss: 1.642\n",
      "[5,   600] loss: 1.620\n",
      "Train Accuracy: 40.77 %\n",
      "[6,   200] loss: 1.573\n",
      "[6,   400] loss: 1.554\n",
      "[6,   600] loss: 1.525\n",
      "Train Accuracy: 43.98 %\n",
      "[7,   200] loss: 1.511\n",
      "[7,   400] loss: 1.480\n",
      "[7,   600] loss: 1.475\n",
      "Train Accuracy: 46.65 %\n",
      "[8,   200] loss: 1.437\n",
      "[8,   400] loss: 1.426\n",
      "[8,   600] loss: 1.406\n",
      "Train Accuracy: 48.47 %\n",
      "[9,   200] loss: 1.393\n",
      "[9,   400] loss: 1.378\n",
      "[9,   600] loss: 1.373\n",
      "Train Accuracy: 50.43 %\n",
      "[10,   200] loss: 1.334\n",
      "[10,   400] loss: 1.352\n",
      "[10,   600] loss: 1.320\n",
      "Train Accuracy: 52.23 %\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 52.48 %\n"
     ]
    }
   ],
   "source": [
    "train(10)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning with threshold : 0.007882364094257355 for layer fc1\n",
      "Pruning with threshold : 0.014518674463033676 for layer fc2\n",
      "Pruning with threshold : 0.02726072259247303 for layer fc3\n",
      "Accuracy of the network on the 10000 test images: 52.56 %\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "      MaskedLinear-5                  [-1, 120]          48,120\n",
      "      MaskedLinear-6                   [-1, 84]          10,164\n",
      "      MaskedLinear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net.prune_by_std()\n",
    "test()\n",
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(initial_optimizer_state_dict) \n",
    "train(10)\n",
    "#print(params[4])\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
