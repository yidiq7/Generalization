{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10RandomLabels(datasets.CIFAR10):\n",
    "    \"\"\"CIFAR10 dataset, with support for randomly corrupt labels.\n",
    "    Params\n",
    "    ------  \n",
    "    corrupt_prob: float\n",
    "    Default 0.0. The probability of a label being replaced with\n",
    "    random label.\n",
    "    num_classes: int\n",
    "    Default 10. The number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, corrupt_prob=0.0, num_classes=10, **kwargs):\n",
    "        super(CIFAR10RandomLabels, self).__init__(**kwargs)\n",
    "        self.n_classes = num_classes\n",
    "        if corrupt_prob > 0:\n",
    "            self.corrupt_labels(corrupt_prob)\n",
    "\n",
    "    def corrupt_labels(self, corrupt_prob):\n",
    "        labels = np.array(self.targets)\n",
    "        np.random.seed(12345)\n",
    "        mask = np.random.rand(len(labels)) <= corrupt_prob\n",
    "        rnd_labels = np.random.choice(self.n_classes, mask.sum())\n",
    "        labels[mask] = rnd_labels\n",
    "        # we need to explicitly cast the labels from npy.int64 to\n",
    "        # builtin int type, otherwise pytorch will fail...\n",
    "        labels = [int(x) for x in labels]\n",
    "        self.targets = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        CIFAR10RandomLabels(root='./data', train=True, download=True, \n",
    "                            transform=transform, corrupt_prob=0.1),\n",
    "                            batch_size=64, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "        CIFAR10RandomLabels(root='./data', train=False, download=True,\n",
    "                            transform=transform, corrupt_prob=0.1),\n",
    "                            batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.mask_flag = False\n",
    "    \n",
    "    def set_mask(self, mask):\n",
    "        self.mask = Variable(mask, requires_grad=False)\n",
    "        self.weight.data = self.weight.data*self.mask.data\n",
    "        self.mask_flag = True\n",
    "    \n",
    "    def get_mask(self):\n",
    "        print(self.mask_flag)\n",
    "        return self.mask\n",
    "    \n",
    "    def prune(self, threshold):\n",
    "        # generate mask\n",
    "        for params in self.parameters():\n",
    "            if len(params.data.size()) != 1: # Not bias\n",
    "                mask = params.data.abs() > threshold\n",
    "                self.set_mask(mask.float()) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mask_flag == True:\n",
    "            weight = self.weight*self.mask\n",
    "            return F.linear(x, weight, self.bias)\n",
    "        else:\n",
    "            return F.linear(x, self.weight, self.bias)\n",
    "        \n",
    "\n",
    "        \n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(MaskedConv2d, self).__init__(in_channels, out_channels, \n",
    "            kernel_size, stride, padding, dilation, groups, bias)\n",
    "        self.mask_flag = False\n",
    "    \n",
    "    def set_mask(self, mask):\n",
    "        self.mask = Variable(mask, requires_grad=False)\n",
    "        self.weight.data = self.weight.data*self.mask.data\n",
    "        self.mask_flag = True\n",
    "    \n",
    "    def get_mask(self):\n",
    "        print(self.mask_flag)\n",
    "        return self.mask\n",
    "    \n",
    "    def prune(self, threshold):\n",
    "        # generate mask\n",
    "        for params in self.parameters():\n",
    "            if len(params.data.size()) != 1: # Not bias\n",
    "                mask = params.data.abs() > threshold\n",
    "                self.set_mask(mask.float()) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mask_flag == True:\n",
    "            weight = self.weight*self.mask\n",
    "            return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "        else:\n",
    "            return F.conv2d(x, self.weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): MaskedConv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): MaskedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): MaskedLinear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): MaskedLinear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): MaskedLinear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        linear = MaskedLinear\n",
    "        conv2d = MaskedConv2d\n",
    "        self.conv1 = conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = conv2d(6, 16, 5)\n",
    "        self.fc1 = linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = linear(120, 84)\n",
    "        self.fc3 = linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def weight_prune(self, pruning_perc):\n",
    "        all_weights = []\n",
    "        for params in self.parameters():\n",
    "            if len(params.data.size()) != 1:\n",
    "                all_weights += list(params.cpu().data.abs().numpy().flatten())\n",
    "        threshold = np.percentile(np.array(all_weights), pruning_perc)\n",
    "        print(f'Pruning with threshold : %.4f' % threshold)\n",
    "        \n",
    "        # Module here refers to layer\n",
    "        for name, module in self.named_modules():\n",
    "            if name in ['conv1','conv2','fc1','fc2','fc3']:\n",
    "                module.prune(threshold)                \n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "#summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, early_stop_step=0):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        step_counter = 0\n",
    "        best_accuracy = 0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 200 mini-batches\n",
    "                #print('[%d, %5d] loss: %.3f' %\n",
    "                #      (epoch + 1, i + 1, running_loss / 200))\n",
    "                train_loss = running_loss / 200\n",
    "                running_loss = 0.0\n",
    "                \n",
    "            # training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        #print('Train Accuracy: %.3f %%' % train_accuracy)\n",
    "        \n",
    "        if early_stop_step != 0:\n",
    "            step_counter += 1\n",
    "            if best_accuracy < train_accuracy:\n",
    "                best_accuracy = train_accuracy\n",
    "                step_counter = 0\n",
    "            if step_counter == early_stop_step or epoch == epochs - 1:\n",
    "                print(\"Early stop at epoch %d\" % (epoch + 1))\n",
    "                print('Train Accuracy: %.3f %%, Train Loss: %.3f' % (train_accuracy, train_loss))\n",
    "                break\n",
    "        \n",
    "        if train_accuracy - 100.0 < 0.001 and train_loss - 0.0 < 0.001:\n",
    "            print(\"Reach 100 %% train accuracy at epoch %d\" % (epoch + 1))\n",
    "            break\n",
    "            \n",
    "    #print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    #print('Test Accuracy on 10000 images: %.2f %%' % (\n",
    "    #    100 * correct / total))\n",
    "    \n",
    "    # test loss for 100 mini-batches)\n",
    "    print('Test Accuracy: %.3f %%, Test Loss: %.3f' % (100 * correct / total, test_loss / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_size(model):\n",
    "    non_zeros = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            non_zeros += param.nonzero().size(0)\n",
    "    params_size = non_zeros* 4. / (1024 ** 2)\n",
    "    print(\"Params size (MB): %0.3f\" % params_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 24.590 %, Test Loss: 2.081\n",
      "Params size (MB): 0.237\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Softmax is built in it so you do not need add that on the last layer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#initial_optimizer_state_dict = optimizer.state_dict()\n",
    "train(net, 1000)\n",
    "model_path = \"models/LeNet.pt\"\n",
    "torch.save(net.state_dict(), model_path)\n",
    "test(net)\n",
    "calculate_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Prune the model by 50 %\n",
      "Pruning with threshold : 0.0279\n",
      "Params size (MB): 0.119\n",
      "Early stop at epoch 2\n",
      "Train Accuracy: 28.384 %, Train Loss: 1.975\n",
      "Test Accuracy: 30.760 %, Test Loss: 1.939\n",
      "--------------------------------------\n",
      "Prune the model by 60 %\n",
      "Pruning with threshold : 0.0335\n",
      "Params size (MB): 0.095\n",
      "Early stop at epoch 2\n",
      "Train Accuracy: 27.658 %, Train Loss: 1.988\n",
      "Test Accuracy: 29.480 %, Test Loss: 1.956\n",
      "--------------------------------------\n",
      "Prune the model by 70 %\n",
      "Pruning with threshold : 0.0391\n",
      "Params size (MB): 0.072\n",
      "Early stop at epoch 2\n",
      "Train Accuracy: 26.638 %, Train Loss: 2.012\n",
      "Test Accuracy: 28.060 %, Test Loss: 1.978\n",
      "--------------------------------------\n",
      "Prune the model by 80 %\n",
      "Pruning with threshold : 0.0448\n",
      "Params size (MB): 0.048\n",
      "Early stop at epoch 2\n",
      "Train Accuracy: 25.314 %, Train Loss: 2.035\n",
      "Test Accuracy: 27.330 %, Test Loss: 2.015\n",
      "--------------------------------------\n",
      "Prune the model by 90 %\n",
      "Pruning with threshold : 0.0534\n",
      "Params size (MB): 0.024\n",
      "Early stop at epoch 2\n",
      "Train Accuracy: 23.514 %, Train Loss: 2.074\n",
      "Test Accuracy: 24.590 %, Test Loss: 2.067\n"
     ]
    }
   ],
   "source": [
    "for prune_percent in [50, 60, 70, 80, 90]:\n",
    "    net_p = Net()\n",
    "    net_p.load_state_dict(torch.load(model_path))\n",
    "    net_p.to(device)\n",
    "    net_p.eval()\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Prune the model by %.2f %%\" % prune_percent)\n",
    "    net_p.weight_prune(prune_percent)\n",
    "    #summary(net, (3, 32, 32))\n",
    "    calculate_size(net_p)\n",
    "    optimizer = optim.SGD(net_p.parameters(), lr=0.001, momentum=0.9)\n",
    "    train(net_p, 3000, early_stop_step=100)\n",
    "    test(net_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
